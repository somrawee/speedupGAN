{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-20 11:53:45.623462\n",
      "2023-12-20 11:53:55.628899\n",
      "0.16675728333333334\n",
      "10.005437\n",
      "0.0027792880555555554\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE CODE RUNNING TIME\n",
    "#-----------------------------\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "start_time = datetime.now()\n",
    "time.sleep(10)\n",
    "stop_time = datetime.now()\n",
    "\n",
    "duration_time = stop_time - start_time\n",
    "\n",
    "print(start_time)\n",
    "print(stop_time)\n",
    "\n",
    "duration_min = duration_time /timedelta(minutes=1)\n",
    "print(duration_min)\n",
    "\n",
    "duration_sec = duration_time/timedelta(seconds=1)\n",
    "print(duration_sec)\n",
    "\n",
    "duration_hour = duration_time/timedelta(hours=1)\n",
    "print(duration_hour)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(519, shape=(), dtype=int32)\n",
      "Actual Batch Size: 519\n",
      "(519, 128)\n",
      "tf.Tensor(\n",
      "[-1.4871933  -1.2193456  -1.0931298   0.3134588  -0.9828173  -0.85445035\n",
      " -0.17216101  0.08176717  1.2010393  -0.14036445 -1.396195    0.08291621\n",
      "  0.45589358 -0.12847921  2.4171002  -0.16919531 -0.6310601  -0.09489875\n",
      "  0.62672806  0.55508155  0.31611416 -0.42744914  1.2977555   0.28610364\n",
      " -0.45686895 -0.05513221 -0.60126936  0.60249007 -1.1287184  -0.356295\n",
      " -0.45268607 -2.687976    1.9919581  -0.9121167   1.6352527   0.5422694\n",
      "  0.2777701   0.13700607  1.2489372   0.00372699  0.10653062 -0.03905092\n",
      "  0.91087437 -1.1068051  -2.302762   -1.7385552  -0.9012104  -0.71283996\n",
      "  0.43237004  0.28594548  0.3341228   0.58921224  0.5453796   1.4216803\n",
      "  0.84067297  0.14140226  1.066232    0.61144286  0.03904763  0.9101565\n",
      "  1.2916627  -1.2925882  -0.32512507  1.150981    2.059253    1.6354314\n",
      " -0.64436793  0.38919193 -0.5838854  -0.46555036 -0.15963688  0.08034204\n",
      "  0.17124388 -0.5092149  -0.6525792   0.49828118  1.9939692   0.6349321\n",
      " -0.03154054 -0.04445703 -1.2716345  -0.84341896 -0.25423726 -2.0495884\n",
      "  1.3695277   0.70499617 -1.6904131  -0.5327755   1.7607818   0.5277952\n",
      "  0.9217352  -1.9225279  -0.08354288 -0.19063169  1.0484182   0.08129194\n",
      " -0.26489142  0.10081584  0.36288065  0.8443404  -0.38303688 -0.51014316\n",
      "  2.0239272   0.29620516  0.94742197  1.073773   -0.868232   -1.0796156\n",
      " -0.8431544  -0.24479865  0.16787617  0.83522755 -1.311983   -0.31878906\n",
      " -1.8734803  -0.0872445  -1.4262124  -0.3979913   0.17531122 -0.7514632\n",
      "  0.45390818 -0.5006847   0.9878131   0.50925344  0.6073917   1.0960966\n",
      "  0.7362899  -0.30455172], shape=(128,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow import Session\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "X_train = []\n",
    "image_path = \"/Users/somrawee/Coding/DataSet/CastingProduct/casting_512x512/casting_512x512/ok_front\"\n",
    "#print(image_path)\n",
    "image_names = os.listdir(image_path)\n",
    "for i in image_names:\n",
    "    #print(i)\n",
    "    img = Image.open(image_path + '/' + i)\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.asarray(img)\n",
    "    X_train.append(img)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "dataset = X_train \n",
    "\n",
    "batch_size = tf.shape(dataset)[0]\n",
    "print(batch_size)\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Assuming batch_size is defined as described above\n",
    "actual_batch_size = batch_size.numpy()\n",
    "print(\"Actual Batch Size:\", actual_batch_size)\n",
    "\n",
    "random_latent_vectors0 = tf.random.normal(shape=(batch_size, 128))\n",
    "print(random_latent_vectors0.shape)\n",
    "print(random_latent_vectors0[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.687976\n",
      "2.4171002\n"
     ]
    }
   ],
   "source": [
    "print(np.min(random_latent_vectors0[0]))\n",
    "print(np.max(random_latent_vectors0[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Randomly select 32 values\n",
    "random_values = np.random.choice(original_array.flatten(), size=32, replace=False)\n",
    "\n",
    "# Reshape the selected values back to the original array shape\n",
    "selected_values = random_values.reshape((32, -1))\n",
    "\n",
    "# Print the selected values\n",
    "print(\"Randomly Selected 32 Values:\")\n",
    "print(selected_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
