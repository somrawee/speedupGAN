{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "encoding_dim = 32\n",
    "#input_img = keras.Input(shape=(28,28,1))\n",
    "input_img = keras.Input(shape=(128,128,3))\n",
    "\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 64, 64, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 64, 64, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 32, 32, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 32, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 16, 16, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 16, 16, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 8, 8, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 8, 8, 8)           584       \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 4, 4, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 4, 4, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_9 (UpSampling  (None, 8, 8, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 8, 8, 8)           584       \n",
      "                                                                 \n",
      " up_sampling2d_10 (UpSamplin  (None, 16, 16, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 16, 16, 8)         584       \n",
      "                                                                 \n",
      " up_sampling2d_11 (UpSamplin  (None, 32, 32, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 8)         584       \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 64, 64, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 64, 64, 16)        1168      \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 128, 128, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 128, 128, 3)       435       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,299\n",
      "Trainable params: 7,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# DATASET = mnist\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32')/ 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(519, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "X_train = []\n",
    "dataset_path = \"/Users/somrawee/Coding/DataSet/CastingProduct/casting_512x512/casting_512x512/ok_front\"\n",
    "\n",
    "image_names = os.listdir(dataset_path)\n",
    "\n",
    "for i in image_names:\n",
    "    img = Image.open(dataset_path + '/' + i)\n",
    "    img = img.resize((128, 128))\n",
    "    img = np.asarray(img)\n",
    "    X_train.append(img)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_train = (X_train.astype(np.float32)-127.5) /127.5\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(415, 128, 128, 3)\n",
      "(104, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset = X_train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 13:08:16.335364: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<128x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<128x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<128x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<128x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<128x128x128x3xi1>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<31x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<31x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<31x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<31x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<31x128x128x3xi1>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 0.6926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 13:08:18.451458: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 462ms/step - loss: 0.6926 - val_loss: 0.6901\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<104x128x128x3xi1>'\n",
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/495c257e-668e-11ee-93ce-926038f30c31/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<104x128x128x3xi1>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 186ms/step - loss: 0.6889 - val_loss: 0.6848\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 1s 178ms/step - loss: 0.6820 - val_loss: 0.6710\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 1s 177ms/step - loss: 0.6616 - val_loss: 0.6192\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 1s 166ms/step - loss: 0.5822 - val_loss: 0.4385\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.3557 - val_loss: 0.1952\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.1914 - val_loss: 0.0882\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: 0.0267 - val_loss: -0.2577\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -0.4461 - val_loss: -1.4520\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -2.3257 - val_loss: -5.9302\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -8.8226 - val_loss: -22.8591\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -34.4360 - val_loss: -81.3292\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 1s 167ms/step - loss: -120.2467 - val_loss: -275.6595\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 1s 163ms/step - loss: -386.3995 - val_loss: -898.8190\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 1s 166ms/step - loss: -1271.4181 - val_loss: -2778.4019\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 1s 163ms/step - loss: -3867.3682 - val_loss: -8201.6338\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -11148.7627 - val_loss: -23043.1348\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -31003.3184 - val_loss: -62107.2891\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -81115.0859 - val_loss: -160579.7031\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 1s 170ms/step - loss: -211998.2500 - val_loss: -396201.3125\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 1s 172ms/step - loss: -512759.1250 - val_loss: -942710.7500\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -1192329.0000 - val_loss: -2170917.2500\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -2696529.0000 - val_loss: -4839687.0000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 1s 168ms/step - loss: -5971442.0000 - val_loss: -10445822.0000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 1s 166ms/step - loss: -12855411.0000 - val_loss: -21897634.0000\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 1s 166ms/step - loss: -26885256.0000 - val_loss: -44644560.0000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 1s 170ms/step - loss: -53843836.0000 - val_loss: -88560840.0000\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 1s 168ms/step - loss: -106803024.0000 - val_loss: -171903136.0000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -204865888.0000 - val_loss: -326504256.0000\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 1s 166ms/step - loss: -385420064.0000 - val_loss: -606713792.0000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -711677312.0000 - val_loss: -1103280384.0000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -1283436288.0000 - val_loss: -1965518848.0000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -2264845568.0000 - val_loss: -3435112192.0000\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 1s 168ms/step - loss: -3979362304.0000 - val_loss: -5904414208.0000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 1s 166ms/step - loss: -6783083520.0000 - val_loss: -9974258688.0000\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 1s 163ms/step - loss: -11434870784.0000 - val_loss: -16618169344.0000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -18946123776.0000 - val_loss: -27288520704.0000\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -30851063808.0000 - val_loss: -44118499328.0000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -49653743616.0000 - val_loss: -70322479104.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -79106301952.0000 - val_loss: -110485651456.0000\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -123245568000.0000 - val_loss: -171484151808.0000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 1s 165ms/step - loss: -191962644480.0000 - val_loss: -262780567552.0000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 1s 164ms/step - loss: -291330686976.0000 - val_loss: -398348255232.0000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 1s 171ms/step - loss: -442619101184.0000 - val_loss: -598041821184.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 1s 175ms/step - loss: -658815188992.0000 - val_loss: -887524753408.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 1s 168ms/step - loss: -974206337024.0000 - val_loss: -1306745241600.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 1s 169ms/step - loss: -1435563720704.0000 - val_loss: -1907336937472.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 1s 171ms/step - loss: -2076680781824.0000 - val_loss: -2758687326208.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 1s 177ms/step - loss: -3016789852160.0000 - val_loss: -3953168220160.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 1s 168ms/step - loss: -4289556119552.0000 - val_loss: -5624190468096.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16595edd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[TensorBoard(log_dir='/Users/somrawee/Coding/logs')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot latent space of test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/17 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 13:49:37.320485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 12ms/step\n",
      "(519, 4, 4, 8)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "#encoded_imgs = encoder.predict(x_test)\n",
    "encoded_imgs = encoder.predict(dataset)\n",
    "\n",
    "print(encoded_imgs.shape)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(encoded_imgs[i].reshape((4, 4 * 8)).T)\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    \n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(519, 4, 4, 8)\n",
      "(519, 128)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_imgs.shape)\n",
    "\n",
    "reshaped_encoded_imgs = np.reshape(encoded_imgs, (encoded_imgs.shape[0], 128))\n",
    "\n",
    "print(reshaped_encoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.67746125e+05 2.31167672e+05 2.33645203e+05 ... 2.79550079e+02\n",
      "    3.08149125e+05 2.07939750e+05]\n",
      "   [8.17553875e+05 1.07866238e+06 1.17442512e+06 ... 2.79511000e+05\n",
      "    1.28414762e+06 6.87996875e+05]\n",
      "   [1.03456831e+06 1.32581988e+06 1.45285050e+06 ... 8.02424688e+05\n",
      "    1.53193825e+06 6.45759438e+05]\n",
      "   [5.41940250e+05 6.49640312e+05 7.25634375e+05 ... 6.43181938e+05\n",
      "    6.74672188e+05 2.22946699e+04]]\n",
      "\n",
      "  [[9.70955625e+05 1.12511250e+06 1.20805712e+06 ... 0.00000000e+00\n",
      "    1.37717212e+06 1.01295362e+06]\n",
      "   [3.26270025e+06 3.52017875e+06 3.91690500e+06 ... 1.30556362e+06\n",
      "    4.09379425e+06 2.16829425e+06]\n",
      "   [3.75631150e+06 3.94970950e+06 4.37816400e+06 ... 2.31794650e+06\n",
      "    4.61454600e+06 2.04080800e+06]\n",
      "   [1.87367850e+06 1.84459288e+06 2.05188338e+06 ... 1.88290800e+06\n",
      "    2.11304100e+06 1.95246531e+05]]\n",
      "\n",
      "  [[1.26310850e+06 1.38904662e+06 1.51887588e+06 ... 0.00000000e+00\n",
      "    1.64690438e+06 1.26322062e+06]\n",
      "   [3.80774000e+06 4.02551500e+06 4.48677050e+06 ... 1.57819512e+06\n",
      "    4.67314650e+06 2.47913700e+06]\n",
      "   [4.23525700e+06 4.39330050e+06 4.87905350e+06 ... 2.57779975e+06\n",
      "    5.10040550e+06 2.27490950e+06]\n",
      "   [2.02158162e+06 1.91203650e+06 2.12496350e+06 ... 1.96654725e+06\n",
      "    2.23890650e+06 1.84046547e+05]]\n",
      "\n",
      "  [[7.95877188e+05 7.98207938e+05 8.99003125e+05 ... 0.00000000e+00\n",
      "    8.78938438e+05 7.48015938e+05]\n",
      "   [2.60081250e+06 2.49284625e+06 2.80613750e+06 ... 9.77957750e+05\n",
      "    2.88032950e+06 1.65116212e+06]\n",
      "   [2.74830175e+06 2.54135300e+06 2.86806000e+06 ... 1.52881425e+06\n",
      "    2.96683200e+06 1.35218900e+06]\n",
      "   [9.49140062e+05 8.02999500e+05 8.74200125e+05 ... 8.49510250e+05\n",
      "    1.01206088e+06 4.52003438e+04]]]\n",
      "\n",
      "\n",
      " [[[4.49139531e+05 6.26949562e+05 6.41231250e+05 ... 0.00000000e+00\n",
      "    8.20625250e+05 5.53641500e+05]\n",
      "   [1.60199912e+06 1.94924262e+06 2.14312400e+06 ... 7.02340625e+05\n",
      "    2.27959675e+06 1.07184862e+06]\n",
      "   [1.75877425e+06 2.07712788e+06 2.29296975e+06 ... 1.20860238e+06\n",
      "    2.41653675e+06 9.91653812e+05]\n",
      "   [9.26878125e+05 1.05577925e+06 1.17683788e+06 ... 9.45220188e+05\n",
      "    1.15265838e+06 1.36730078e+05]]\n",
      "\n",
      "  [[1.69532738e+06 1.87052588e+06 2.06790888e+06 ... 0.00000000e+00\n",
      "    2.22961300e+06 1.67278712e+06]\n",
      "   [3.79542475e+06 3.96850725e+06 4.39761550e+06 ... 1.75155788e+06\n",
      "    4.60780250e+06 2.21315575e+06]\n",
      "   [3.85775400e+06 4.02596025e+06 4.46221450e+06 ... 2.23511000e+06\n",
      "    4.69601900e+06 2.16451900e+06]\n",
      "   [2.39536050e+06 2.38886925e+06 2.66026950e+06 ... 2.01218188e+06\n",
      "    2.78726625e+06 6.15748750e+05]]\n",
      "\n",
      "  [[1.77689938e+06 1.90818250e+06 2.10710650e+06 ... 0.00000000e+00\n",
      "    2.23238800e+06 1.70588838e+06]\n",
      "   [3.78463000e+06 3.89783350e+06 4.32990250e+06 ... 1.74467588e+06\n",
      "    4.56442650e+06 2.21873025e+06]\n",
      "   [3.81429500e+06 3.92695575e+06 4.36820500e+06 ... 2.19415200e+06\n",
      "    4.54815250e+06 2.09478850e+06]\n",
      "   [2.37524100e+06 2.26755400e+06 2.52636750e+06 ... 1.90044138e+06\n",
      "    2.66653775e+06 6.23548500e+05]]\n",
      "\n",
      "  [[7.80293062e+05 7.58434312e+05 8.75391875e+05 ... 0.00000000e+00\n",
      "    8.09335750e+05 7.07908875e+05]\n",
      "   [1.95707588e+06 1.84248838e+06 2.07191000e+06 ... 7.45227500e+05\n",
      "    2.12933850e+06 1.17032125e+06]\n",
      "   [1.96634862e+06 1.83917600e+06 2.06783200e+06 ... 1.07099712e+06\n",
      "    2.13995800e+06 1.05360538e+06]\n",
      "   [9.20800562e+05 8.01049750e+05 8.90747875e+05 ... 7.37231875e+05\n",
      "    9.80348875e+05 1.95919781e+05]]]\n",
      "\n",
      "\n",
      " [[[4.38421406e+05 6.35254062e+05 6.66422875e+05 ... 0.00000000e+00\n",
      "    8.11835062e+05 5.44042562e+05]\n",
      "   [1.06248400e+06 1.40253938e+06 1.53734712e+06 ... 6.18393062e+05\n",
      "    1.61098888e+06 7.37385188e+05]\n",
      "   [9.22581188e+05 1.21382938e+06 1.34521462e+06 ... 7.82436375e+05\n",
      "    1.34683862e+06 4.42785750e+05]\n",
      "   [2.48672859e+05 2.92088531e+05 3.23746312e+05 ... 2.95046906e+05\n",
      "    2.94939531e+05 0.00000000e+00]]\n",
      "\n",
      "  [[2.06568488e+06 2.27538125e+06 2.54477325e+06 ... 2.66874625e+05\n",
      "    2.67221850e+06 1.87501025e+06]\n",
      "   [3.38695925e+06 3.47688400e+06 3.84605500e+06 ... 1.54084738e+06\n",
      "    4.05497350e+06 1.85073212e+06]\n",
      "   [3.16683750e+06 3.29556250e+06 3.63661450e+06 ... 2.08520988e+06\n",
      "    3.90880650e+06 1.77266938e+06]\n",
      "   [1.33212550e+06 1.31680888e+06 1.45902900e+06 ... 1.37467688e+06\n",
      "    1.49284238e+06 0.00000000e+00]]\n",
      "\n",
      "  [[2.31037425e+06 2.47196675e+06 2.76142275e+06 ... 3.66714438e+05\n",
      "    2.89836750e+06 2.04451950e+06]\n",
      "   [3.42307075e+06 3.59454300e+06 3.96459475e+06 ... 1.60652650e+06\n",
      "    4.17126650e+06 1.90777050e+06]\n",
      "   [3.39502400e+06 3.55782475e+06 3.95103825e+06 ... 2.26314475e+06\n",
      "    4.12670825e+06 1.97898250e+06]\n",
      "   [1.62571312e+06 1.53165925e+06 1.69824712e+06 ... 1.59898325e+06\n",
      "    1.79507538e+06 4.49863438e+04]]\n",
      "\n",
      "  [[1.13370275e+06 1.13094312e+06 1.27236862e+06 ... 2.25307129e+04\n",
      "    1.21949388e+06 1.00549712e+06]\n",
      "   [2.27583050e+06 2.06927900e+06 2.33613025e+06 ... 9.47525375e+05\n",
      "    2.42716725e+06 1.25164125e+06]\n",
      "   [2.14526700e+06 1.92512375e+06 2.18170475e+06 ... 1.16268750e+06\n",
      "    2.25065975e+06 1.05314850e+06]\n",
      "   [7.17626500e+05 5.94202188e+05 6.47401438e+05 ... 6.31315750e+05\n",
      "    7.64578000e+05 4.03873984e+04]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.66233325e+06 1.84009025e+06 2.02447212e+06 ... 4.53687148e+04\n",
      "    2.18894075e+06 1.48462712e+06]\n",
      "   [3.18339500e+06 3.48408600e+06 3.85313250e+06 ... 1.53109550e+06\n",
      "    4.06905600e+06 1.92487625e+06]\n",
      "   [3.04271475e+06 3.28969975e+06 3.66726675e+06 ... 1.83491800e+06\n",
      "    3.81254700e+06 1.53960775e+06]\n",
      "   [1.47864150e+06 1.49290488e+06 1.66115312e+06 ... 1.27740538e+06\n",
      "    1.71900788e+06 2.91941000e+05]]\n",
      "\n",
      "  [[1.86321938e+06 2.03312638e+06 2.21103250e+06 ... 0.00000000e+00\n",
      "    2.43505425e+06 1.73519338e+06]\n",
      "   [4.34715750e+06 4.54381150e+06 5.04989400e+06 ... 1.99773288e+06\n",
      "    5.27645300e+06 2.59629750e+06]\n",
      "   [4.34056000e+06 4.51669650e+06 5.00387500e+06 ... 2.70257250e+06\n",
      "    5.26321000e+06 2.30618375e+06]\n",
      "   [1.96004375e+06 1.88688212e+06 2.09419475e+06 ... 1.82158650e+06\n",
      "    2.17131950e+06 2.47168078e+05]]\n",
      "\n",
      "  [[1.62444125e+06 1.72513112e+06 1.88255850e+06 ... 0.00000000e+00\n",
      "    2.03384350e+06 1.55712862e+06]\n",
      "   [4.28123050e+06 4.47391300e+06 4.97418850e+06 ... 1.91506138e+06\n",
      "    5.24327250e+06 2.57215375e+06]\n",
      "   [4.37789600e+06 4.54022300e+06 5.05353050e+06 ... 2.75793100e+06\n",
      "    5.26309300e+06 2.32038125e+06]\n",
      "   [1.90665788e+06 1.77564138e+06 1.96847275e+06 ... 1.82162212e+06\n",
      "    2.08720850e+06 6.37546953e+04]]\n",
      "\n",
      "  [[5.93043000e+05 5.63035625e+05 6.61906812e+05 ... 4.33563202e+02\n",
      "    5.84107062e+05 5.55592625e+05]\n",
      "   [2.27692325e+06 2.11322750e+06 2.40048000e+06 ... 8.04219562e+05\n",
      "    2.41995400e+06 1.46877538e+06]\n",
      "   [2.38411625e+06 2.14610375e+06 2.42370075e+06 ... 1.28472950e+06\n",
      "    2.50758675e+06 1.18553112e+06]\n",
      "   [7.68116375e+05 6.25456562e+05 6.86120625e+05 ... 6.72556375e+05\n",
      "    8.14542875e+05 3.57097617e+04]]]\n",
      "\n",
      "\n",
      " [[[7.03360000e+05 8.97622812e+05 9.65291500e+05 ... 0.00000000e+00\n",
      "    1.10400825e+06 6.77182500e+05]\n",
      "   [1.48801812e+06 1.81593538e+06 1.99455488e+06 ... 7.87441125e+05\n",
      "    2.11310325e+06 9.64585875e+05]\n",
      "   [1.48256238e+06 1.80028500e+06 1.97505175e+06 ... 9.81989750e+05\n",
      "    2.08815025e+06 7.90498812e+05]\n",
      "   [7.23654688e+05 8.48597312e+05 9.51866250e+05 ... 8.20090875e+05\n",
      "    9.00118875e+05 8.54209844e+04]]\n",
      "\n",
      "  [[2.31005125e+06 2.51915425e+06 2.79329225e+06 ... 3.34872500e+05\n",
      "    2.96891350e+06 1.84587038e+06]\n",
      "   [3.74896550e+06 3.90456875e+06 4.33495750e+06 ... 1.83401925e+06\n",
      "    4.52733350e+06 2.17259525e+06]\n",
      "   [3.73825625e+06 3.88302825e+06 4.30129300e+06 ... 2.10089875e+06\n",
      "    4.53585250e+06 2.02588762e+06]\n",
      "   [2.11216175e+06 2.07810562e+06 2.32822925e+06 ... 2.09086462e+06\n",
      "    2.40222125e+06 4.15872719e+05]]\n",
      "\n",
      "  [[2.50499725e+06 2.62635425e+06 2.91699050e+06 ... 3.40161062e+05\n",
      "    3.08113550e+06 1.98333038e+06]\n",
      "   [3.86319475e+06 3.99219225e+06 4.43787150e+06 ... 1.90940575e+06\n",
      "    4.65877700e+06 2.28771900e+06]\n",
      "   [3.81181375e+06 3.95157775e+06 4.38675700e+06 ... 2.18085275e+06\n",
      "    4.58339750e+06 2.06699112e+06]\n",
      "   [2.15457000e+06 2.03836575e+06 2.27937150e+06 ... 2.07390338e+06\n",
      "    2.39558375e+06 3.85519531e+05]]\n",
      "\n",
      "  [[1.11598962e+06 1.08053962e+06 1.23391838e+06 ... 6.54844023e+04\n",
      "    1.18509025e+06 9.07934125e+05]\n",
      "   [2.10136050e+06 1.93401538e+06 2.18611100e+06 ... 9.21798312e+05\n",
      "    2.23908625e+06 1.19873762e+06]\n",
      "   [2.00609150e+06 1.81135525e+06 2.05073938e+06 ... 1.03222881e+06\n",
      "    2.10299450e+06 9.93353875e+05]\n",
      "   [7.68188375e+05 6.51725312e+05 7.09877375e+05 ... 6.74613188e+05\n",
      "    8.28853750e+05 1.06059484e+05]]]\n",
      "\n",
      "\n",
      " [[[3.14195344e+05 4.45710906e+05 4.53551469e+05 ... 6.59087097e+02\n",
      "    5.99687938e+05 3.98601438e+05]\n",
      "   [1.14362962e+06 1.53405712e+06 1.67770938e+06 ... 5.58284375e+05\n",
      "    1.78149812e+06 8.41031250e+05]\n",
      "   [1.16778425e+06 1.51968638e+06 1.68060288e+06 ... 9.25244188e+05\n",
      "    1.71469388e+06 6.10820312e+05]\n",
      "   [3.79130375e+05 4.55347875e+05 5.03927000e+05 ... 4.57258188e+05\n",
      "    4.59722562e+05 0.00000000e+00]]\n",
      "\n",
      "  [[1.56657538e+06 1.75006662e+06 1.91160712e+06 ... 0.00000000e+00\n",
      "    2.11257150e+06 1.56898425e+06]\n",
      "   [3.96558450e+06 4.15181450e+06 4.60557050e+06 ... 1.82315925e+06\n",
      "    4.81763050e+06 2.33344150e+06]\n",
      "   [3.95340750e+06 4.12190875e+06 4.55572850e+06 ... 2.45987525e+06\n",
      "    4.83907550e+06 2.11401725e+06]\n",
      "   [1.75594738e+06 1.73708338e+06 1.92888588e+06 ... 1.75755962e+06\n",
      "    1.99905975e+06 9.40902656e+04]]\n",
      "\n",
      "  [[1.80876438e+06 1.95670425e+06 2.14846575e+06 ... 0.00000000e+00\n",
      "    2.29788650e+06 1.71873550e+06]\n",
      "   [4.15671550e+06 4.33346150e+06 4.80834100e+06 ... 1.92409138e+06\n",
      "    5.05612150e+06 2.48048950e+06]\n",
      "   [4.20672250e+06 4.37589200e+06 4.85406700e+06 ... 2.57328300e+06\n",
      "    5.08387750e+06 2.31200025e+06]\n",
      "   [2.13332775e+06 2.07715488e+06 2.30317100e+06 ... 1.98457462e+06\n",
      "    2.44362175e+06 4.16622656e+05]]\n",
      "\n",
      "  [[1.22403525e+06 1.24237512e+06 1.41029750e+06 ... 4.37838242e+04\n",
      "    1.41018812e+06 1.06150112e+06]\n",
      "   [2.84002700e+06 2.78751075e+06 3.12632675e+06 ... 1.15141750e+06\n",
      "    3.23366225e+06 1.69802862e+06]\n",
      "   [2.95381050e+06 2.87672000e+06 3.22102725e+06 ... 1.61110738e+06\n",
      "    3.34790600e+06 1.60032088e+06]\n",
      "   [1.61864962e+06 1.48620612e+06 1.66162550e+06 ... 1.32214962e+06\n",
      "    1.78012862e+06 3.95050094e+05]]]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "5434446.5\n"
     ]
    }
   ],
   "source": [
    "print(np.min(encoded_imgs[0]))\n",
    "print(np.max(encoded_imgs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(519, 4, 4, 8)\n",
      "-1.6553032\n",
      "2.5052166\n"
     ]
    }
   ],
   "source": [
    "mean_value = np.mean(encoded_imgs)\n",
    "std_dev = np.std(encoded_imgs)\n",
    "\n",
    "# Z-score normalization\n",
    "normalized_array = (encoded_imgs - mean_value) / std_dev\n",
    "\n",
    "print(normalized_array.shape)\n",
    "print(np.min(normalized_array))\n",
    "print(np.max(normalized_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
